---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Weekly Sales Forecasting

The purpose of this project is to forecast weekly sales for each department in 45 stores & also to carry out statistical analysis to help improve financial planning of the national retail store. A forecast is based on historical sales data and is done for a particular period of a time in the near future, usually the next calendar year. A sales forecast enables a company to make informed business decisions regarding inventory or cash flow or plan for growth.

Data transformation and machine learning will be used to create a model that will predict weekly_sales when given information on store, department, date & IsHoliday.

The data for this model is relatively simplified as it has very few missing areas. The raw data consists of a training dataset with the features listed above and their corresponding weekly_sales. Twenty percent of this training dataset was split into a test dataset with corresponding weekly_sales so accuracy and error of the model could be determined.

The features in this data set are described as below:

- Store: The store number
- Dept: The department number
- Date: date of sale
- IsHoliday: Whether the week is a special holdiay week

```{python}
#import required libraries
import pandas as pd
import sklearn as sk
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline 
import warnings
warnings.filterwarnings('ignore')

from scipy.stats import norm
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from statsmodels.tsa.arima_model import ARIMA, ARMAResults
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.externals import joblib

```

# Data Preparation
Define relevant functions needed in the span of the project

```{python}
#function to load the data into a Pandas Dataframe
def load_f(file):
    return pd.read_csv(file)

#scatter plots 
def scatter_data(df, col):
    plt.figure(figsize = (12,8))
    plt.scatter(df[col], df['Weekly_Sales'] )
    plt.ylabel('Weekly_Sales')
    plt.xlabel(col)

#regression plots
def reg_data(df, col):
    plt.figure(figsize=(12,8))
    sns.regplot(x=df[col], y = df['Weekly_Sales'], data = df, line_kws = {'color' : 'red'})    
    plt.ylim(0,)
    
#residual plots 
def res_data(df,col):
    plt.figure(figsize=(12,8))
    sns.residplot(x=df[col], y = df['Weekly_Sales'], data = df)
    plt.show()

#distribution plots 
def dis_data(Rfunction, Bfunction, Rname, Bname, title):
    plt.figure(figsize=(10,6))
    ax1 = sns.distplot(Rfunction, hist = False, color = 'r', label = Rname)
    ax1 = sns.distplot(Bfunction, hist = False, color = 'b', label = Bname)
    plt.title(title)
    plt.show()
    plt.close()
```

# 1. Data Acquisition

```{python}
print("Loading data..")
train_df = load_f('data/train.csv')



#verify data is laoded 
train_df.head()
```

```{python}
train_df.tail()
```

```{python}
train_df.info()
```

```{python}
train_df.describe()
```

```{python}
print(train_df.shape)
```

```{python}
#Number of unique stores in the data set
train_df['Store'].nunique()
```

```{python}
#Number of unique departments in the data set
train_df['Dept'].nunique()
```

# 2. Data Preprocessing

```{python}
train_df.dropna()
```

Check for missing values -

```{python}
#store the sum of missing values in each column - 
missing_val = train_df.isnull().sum()
missing_val
```

```{python}
#convert date feature from object to datetime datatype
train_df['Date'] = pd.to_datetime(train_df['Date'], format="%Y-%m-%d")
```

```{python}
#verify if the conversion executed successfully
train_df.info()
```

# 3. Exploratory Data Analysis

Descriptive statistics of quantitative data

```{python}
train_df.describe()
```

```{python}
train_df.describe()
```

The minimum, maximum and the range of these numbers looks appropriate for their corresponding columns. The mean and standard deviation do not indicate anything wrong.

Are Weekly_Sales normally distributed?


#### Measures of Skewness and Kurtosis
- Skewness is a measure of symmetry, or more precisely, the lack of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.

- Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution. That is, data sets with high kurtosis tend to have heavy tails, or outliers. Data sets with low kurtosis tend to have light tails, or lack of outliers. A uniform distribution would be the extreme case.

```{python}
#compute the kurtosis and skewness of Weekly_Sales
print('Weekly Sales Skewness:', train_df['Weekly_Sales'].skew())
print('Weekly Sales Kurtosis:', train_df['Weekly_Sales'].kurt())
print('\n')
if -0.5 <= train_df['Weekly_Sales'].skew() <= 0.5:
    print('Weekly Sales distribution is approximately symmetric')
elif -0.5 > train_df['Weekly_Sales'].skew() or train_df['Weekly_Sales'].skew() > 0.5:
    print('Weekly_Sales distribution is skewed')
```

#### Visualize target variable - Weekly_Sales


#### The interquartile range (IQR):
is a measure of variability, based on dividing a data set into quartiles.

Quartiles divide a rank-ordered data set into four equal parts. The values that divide each part are called the first, second, and third quartiles; and they are denoted by Q1, Q2, and Q3, respectively.

Q1 is the "middle" value in the first half of the rank-ordered data set.
Q2 is the median value in the set.
Q3 is the "middle" value in the second half of the rank-ordered data set.

```{python}
#We use IQR to identify potential outliers 
stats = train_df['Weekly_Sales'].describe()
IQR = stats['75%'] - stats['25%']
upper_bound = stats['75%'] + 1.5 * IQR
lower_bound = stats['25%'] - 1.5 * IQR
print('The upper and lower bounds of possible outliers:', lower_bound, upper_bound)
```

```{python}
#plot boxplot & distribution plot of the target variable
plt.figure(figsize = (14,6))
plt.subplot(1,2,1)
sns.boxplot(train_df['Weekly_Sales'])
plt.subplot(1,2,2)
sns.distplot(train_df['Weekly_Sales'])
```

As seen by the box plot & distribution plot, the distribution of the target variable, weekly_sales is positively skewed with a lot of outliers. Let us deep-dive into the outliers to understand better.

```{python}
#examine the outliers below the lower_bound
train_df[train_df['Weekly_Sales'] < lower_bound]
```

Looks like we do not have outliers below the lower bound. Next, let us examine the outliers above

```{python}
#examine the outliers above the upper_bound
train_df[train_df['Weekly_Sales'] > upper_bound]
```

Looks like there are a lot of outliers.


#### Feature Engineering on Date feature


Convert Categorical variables into Quantitative variables for better results:

```{python}
#Convert IsHoliday feature into integer values for easier computations
train_df['IsHolidayInt'] = [int(x) for x in list(train_df.IsHoliday)]
```

```{python}
print(train_df.IsHolidayInt)
```

```{python}
from datetime import datetime
#strip year from date feature
train_df['year'] = train_df['Date'].dt.year
train_df.head()
```

```{python}
#strip month from date feature
train_df['month'] = train_df['Date'].dt.month
train_df.head()
```

```{python}
#strip year from date feature
train_df['week_day'] = train_df['Date'].dt.weekday
train_df.head()
```

```{python}
#drop Date column as we already have extracted informations from it - 
train_df = train_df.drop('Date', axis=1)
```

## Visualize features & trends with Weekly_Sales


Amount of Departments across all stores

```{python}
#plot to visualize the variance in departments across all stores
plt.figure(figsize=(15,10))
ax= sns.barplot(train_df.Store, train_df.Dept, alpha=0.8)
sns.barplot(train_df.Store, train_df.Dept)
plt.title("Departments per Store")
plt.show()
```

All the stores seem to have similar amount of departments with slight differences in few. With more information on department types, we could have also visualized the types of departments that are most common across all stores

Now let us get a high-level overview of weekly sales performance of all stores.

```{python}
# plot bar chart to see weekly_sales performance of each store
plt.figure(figsize=(15,10))
ax= sns.barplot(train_df.Store, train_df.Weekly_Sales, alpha=0.8)
plt.title("Sales of stores")
plt.show()
```

By the above plot, we can see that stores - 4, 14 & 20 are the high performing ones. While, 5th & 44th are amongst the lowest. There could be a variety of factors effecting these. With more demographical data of these stores, we would be able to visualize better.

Now let us zoom in to visualize the monthly trends of sales for each year.

```{python}
#plot line plot to visualize the trends of sales of the retail company for each year by months
plt.figure(figsize=(16,8))
plt.title('Weekly_Sales of the company for each Year by Months')
plt.xlabel('Month')
plt.ylabel('Sales')
sns.lineplot(train_df.month, train_df.Weekly_Sales, hue = train_df.year)
```

There is an obvious seasonality, i.e. peak sales at the end of the year



Let us picture how the sales vary year-wise during Thanksgiving time.
i.e October

```{python}
#plot bar chart to visualize sales year-wise for the month of October
october=train_df[train_df['month'] == 10]
plt.figure(figsize=(15,10))
ax= sns.barplot(october.year, october.Weekly_Sales, alpha=0.8)
plt.title("Weekly Sales of stores")
```

Now let us deep dive into performance of stores for each year during Thanksgiving time.



```{python}
#function to plot bar chart of performance of stores for each year during Thanksgiving time-
def thanksgiving_year(year):
    plt.figure(figsize=(15,10))
    plt.title(year)
    mnth = train_df['month'] == 10
    yr = train_df['year'] == year
    october=train_df[mnth & yr]
    ax= sns.barplot(october.Store, october.Weekly_Sales, alpha=0.8)
```

```{python}
#plot bar chart of performance of stores for 2010 during Thanksgiving time
thanksgiving_year(2010)
```

```{python}
#plot bar chart of performance of stores for 2011 during Thanksgiving time
thanksgiving_year(2011)
```

```{python}
#plot bar chart of performance of stores for 2012 during Thanksgiving time
thanksgiving_year(2012)
```

```{python}
#plot line plot to visualize the trends of store performances for each year during Thanksgiving time
plt.figure(figsize=(16,8))
plt.title('Performance of stores during Thanksgiving time by Years')
plt.xlabel('Store')
plt.ylabel('Sales')
mnth = train_df['month'] == 10
october=train_df[mnth]
sns.lineplot(october.Store, october.Weekly_Sales, hue = october.year)
```

This looks like a seasonal trend of sales store-wide across all years during Thanksgiving time in our data.

```{python}
#plot line plot to visualize the trends of store performances for each year during Christmas time
plt.figure(figsize=(16,8))
plt.title('Performance of stores during Christmas time by Years')
plt.xlabel('Store')
plt.ylabel('Sales')
mnth_12 = train_df['month'] == 12
december=train_df[mnth_12]
sns.lineplot(december.Store, december.Weekly_Sales, hue = december.year)
```

```{python}
##plot line plot to visualize the trends of store performances for each year during Super Bowl time
plt.figure(figsize=(16,8))
plt.title('Performance of stores during Super Bowl time by Years')
plt.xlabel('Store')
plt.ylabel('Sales')
mnth_02 = train_df['month'] == 2
feb=train_df[mnth_02]
sns.lineplot(feb.Store, feb.Weekly_Sales, hue = feb.year)
```

```{python}
##plot line plot to visualize the trends of store performances for each year during Labor Day time
plt.figure(figsize=(16,8))
plt.title('Performance of stores during Labor Day time by Years')
plt.xlabel('Store')
plt.ylabel('Sales')
mnth_09 = train_df['month'] == 9
sept=train_df[mnth_09]
sns.lineplot(sept.Store, sept.Weekly_Sales, hue = sept.year)
```

This looks like a seasonal trend of sales store-wide across all years during Labor Day time in our data.

Holiday season, especially Christmas time definitely affect the sales across all stores. However, certain stores have relatively quite low performance. We can possibly understand the reasons for those given more demographical data of all the stores.

Now let us visualize the performance of departments with respect to different stores sorted by date.

```{python}
#plot performance of departments for respective stores sorted by date-
count = 0
for store, dept in train_df.groupby(["Store", "Dept"]):
    plt.ylabel('Weekly_Sales')
    plt.xlabel(store)
    print(dept.shape)
    dept = dept.sort_values(by=['month'])
    plt.scatter(range(len(dept)), dept["Weekly_Sales"])
    plt.show()
    if count > 10:
        break
    count += 1
```

Dept-vs-Weekly_Sales plot shows noticable relations, but no obvious linearality has been observed in any plot.

In the plots of the weekly sales of each store and department, we see different trends in each plot, indicating that the features may affect the weekly sales of each department in each store differently.

Let us visualize the IsHoliday feature.

```{python}
scatter_data(train_df,'IsHoliday')
```

```{python}
#Fit a regression line to IsHoliday feature to visualize them as a predictor of Weekly_Sales - 
reg_data(train_df,'IsHoliday')
```

### Correlation between all the features

```{python}
# Plot heatmap of all data with correlation coefficients vis
train_df_corr = train_df.corr()
plt.subplots(figsize=(20,10))
sns.heatmap(train_df_corr, cmap = 'BuGn', linewidth =.005, annot = True)
```


Pearson correlation coefficient of -1 or +1 also suggest that the relationship between two variables is strong, while two features that are not monotonically related can have a very small correlation coefficient (~0). From the matrix above, we can see that the correlation coefficients between Weekly_Sales and other features are considerbly small, showing that they do not have strong monotonic relations.


# 4. Modelling & evaluation


To create a basic training model, two variables will be assigned for the model to use. Twenty percent of the training data will be split into testing data that we can use to test the model with data for which the Weekly_Sales are already known.

```{python}
#Split the data and assign 'Weekly_Sales' to 'sales_df' and the rest of the features to 'feat_df'. 
feat_df = train_df[train_df.loc[ :, train_df.columns != 'Weekly_Sales'].columns]
sales_df = train_df['Weekly_Sales']
feat_train, feat_test, sales_train, sales_test = train_test_split(feat_df, sales_df, test_size = 0.2, random_state = 1)
```

```{python}
#View inputs and outputs of training model
print('Inputs- \n', feat_train.head())
print('Outputs- \n', sales_train.head())
```

We will use linear regression here as Weekly_Sales is a continious variable. With all the data, we see that this is a case of Supervised Regression learning. We will establish the baseline model by appling Linear Regression to feat_train, sales_train.

```{python}
#Create Linear Regression Object and fit the model
lm = LinearRegression()
lm.fit(feat_train,sales_train)
lm
```

Next, we will view the coefficients of our model -



```{python}
#View coeff of Linear Regression object
print(lm.intercept_)
print(lm.coef_)
```

Now that the baseline model is created, it can predict the salaries. The variable yhat is used to store the predictions using the training data.

```{python}
#predict Weekly_Sales using training data
yhat = lm.predict(feat_train)

#View first five predictions -
print('First five predictions:' , yhat[0:5])
```

Mean squared error (MSE) will be evaluated now along with accuracy and r-squared to evaluate the baseline model's performance and to determine if the subsequent models improve over the established baseline model.

```{python}
#print MSE - 
print('Mean Squared Error of our prediction model', mean_squared_error(sales_train, yhat))
```

```{python}
#print MAE - 

print('Mean Absolute Error of our prediction model', mean_absolute_error(sales_train, yhat))
```

```{python}
# accuracy of the baseline model using 5-cross validation method -
score = cross_val_score(lm, feat_train, sales_train, cv = 5)
print('5-Cross Validation accuracy', (np.mean(score)), (np.std(score)))
```

```{python}
#distribution plot 
Title = 'Distribution PLot of Actual Values vs Predicted Values'
dis_data(sales_train, yhat, 'Actual Values(train data)', 'Predicted Values(train data)', Title)
```

Next, we do the same for the 20% test data to see if the outcome is similar.



```{python}
#store test set predictions in yhat_test 
yhat_test = lm.predict(feat_test)

#view first five predictions - 
print('First five predictions(test data)', yhat_test[0:5])
```

```{python}
#MSE of test data - 
print('Mean Squared Error of test data ', mean_squared_error(sales_test, yhat_test))
```

```{python}
#MAE of test data - 
print('Mean Absolute Error of test data ', mean_absolute_error(sales_test, yhat_test))
```

MAE of test data is slightly more than the MAE of training data

```{python}
#accuracy of test data using 5-cross validation method - 
score = cross_val_score(lm, feat_test, sales_test, cv = 5)
print('5-cross validation accuracy(test data)', (np.mean(score)), (np.std(score)))
```

```{python}
#Distribution plot 
Title = 'Distribution Plot of Predicted values of test data vs Actual values of test data'
dis_data(sales_test, yhat_test, 'Actual Values(test)', 'Predicted Values(test)', title = Title)
```

#### Three models that may improve results over the baseline model are -

- Apply Polynomial Transformation
- Use Ridge Regression
- Use Random Forest


The shape and features of the training data and testing data will be checked before applying models on them.



```{python}
#shape and features -

print('Number of training samples-', feat_train.shape, '\n with the features-', feat_train.columns) 
print('Number of testing samples-', feat_test.shape, '\n with the features-', feat_test.columns)
print('Number of training weekly_sales-', sales_train.shape)
print('Number of testing weekly_sales-', sales_test.shape)
```

We will first apply Polynomial Features to already built Linear regression model and see if MAE reduces.



```{python}
#Fit and transform the variables with 2nd order polynomial
pr = PolynomialFeatures(2)
feat_train_pr = pr.fit_transform(feat_train)
feat_test_pr = pr.fit_transform(feat_test)
pr
```

```{python}
#Create a new model using Polynomial Transformation 
poly = LinearRegression()
poly.fit(feat_train_pr, sales_train)
```

```{python}
#make predictions and view first five predictions on train data - 
yhat_pr = poly.predict(feat_train_pr)
print('First five predictions(train data)-', yhat_pr[0:5])
```

```{python}
#Compare first five predicted values vs actual values - 
print('Predicted Values(train)-', yhat_pr[0:5])
print('Actual Values(train)-', sales_train[0:5].values)
```

```{python}
#make predictions and view first five predictions on test data - 
yhat_prtest = poly.predict(feat_test_pr)
print('First five predictions(test data)-', yhat_prtest[0:5])
```

```{python}
#Compare predicted values of test data and actual values of test data - 
print('Predicted values(test)-', yhat_prtest[0:5])
print('Actual values(test)-', sales_test[0:5].values)
```

```{python}

#print R-squared values of training and testing data - 
print('R-squared of training data-', poly.score(feat_train_pr, sales_train))
print('R-squared of testing data-', poly.score(feat_test_pr, sales_test))
```

```{python}
#MAE of training and testing data - 
print('MAE of training data-', mean_absolute_error(sales_train, yhat_pr))
print('MAE of testing data-', mean_absolute_error(sales_test, yhat_prtest))
```

```{python}
#View distribution plot of actual vs fitted of training data - 
dis_data(sales_test, yhat_pr, 'Actual Values(train)', 'Predicted Values(train)', title = 'Distribution PLot of actual values of training data vs predicted values of training data')
```

```{python}
#view distribution plot of actual vs fitted of testing data - 
dis_data(sales_test, yhat_prtest, 'Actual Values(test)', 'Predicted Values(test)', title = 'Distribution Plot of actual values of testing data vs predicted values of testing data')
```

Now we will check if applying Ridge regression reduces MAE



```{python}
#create a ridge regression object and fit it to training data 
RidgeModel = Ridge(alpha = 1.0)
RidgeModel.fit(feat_train_pr, sales_train)
```

```{python}
#predict values of training data and testing data
yhat_Ridge_train = RidgeModel.predict(feat_train_pr)
yhat_Ridge_test = RidgeModel.predict(feat_test_pr)
```

```{python}
#compare actual and predicted values of training data 
print('Predicted Values(train)-', yhat_Ridge_train[0:5])
print('Actual Values(train)-', sales_train[0:5].values)
```

```{python}
#compare actual and predicted values of testing data 
print('Predicted Values(test)-', yhat_Ridge_test[0:5])
print('Actual Values(test)-', sales_test[0:5].values)
```

```{python}
#R-squared of training and testing data - 
print('R-squared values(train)-', RidgeModel.score(feat_train_pr, sales_train))
print('R-squared values(test)-', RidgeModel.score(feat_test_pr, sales_test))
```

```{python}
#MAE of training and testing data - 
print('MAE of training data-', mean_absolute_error(sales_train, yhat_Ridge_train))
print('MAE of testing data-', mean_absolute_error(sales_test, yhat_Ridge_test))
```

We see no improvement using alpha = 1.0

Let us now use Grid Search to ensure right hyperparameters are used -

```{python}
#define the hyperparameter - 
parameters1 = [{'alpha': [0.001,0.1,1, 10, 100, 1000, 10000, 100000, 100000]}]
parameters1
```

```{python}
#Create a new Ridge Regression object - 
RM = Ridge()
```

```{python}
#create a gridsearch object and pass RM, parameters1 to it. 
Grid = GridSearchCV(RM, parameters1, cv = 5)
```

```{python}
#fit the grid search model to the training data - 
Grid.fit(feat_train, sales_train)
```

```{python}
#assign best estimator - 
bestRM = Grid.best_estimator_
bestRM
```

```{python}
#Test model using test data - 
bestRM.score(feat_test, sales_test)
```


We do not see any significant improvement here. Perhaps the performance could improve if we had more data.

Next let us try using Random Forest and Fit a Randorm Forest with random_state = 1 for consistency

```{python}
#create a random forest object - 
RF = RandomForestRegressor(n_estimators = 150, n_jobs = 2, max_features = 7)
RF
```

```{python}
#fit a Random Forest model on training data - 
RF.fit(feat_train, sales_train)
```

```{python}
#make predictions on testing data and print the first five - 
yhat_RF_test = RF.predict(feat_test)
print('First five predictions-', yhat_RF_test[0:5])
```

```{python}
#R-squared and MAE of test data - 
print('R-squared of test data-', RF.score(feat_test, sales_test))
print('MAE of test data-', mean_absolute_error(sales_test, yhat_RF_test))
```

```{python}
score = cross_val_score(RF, feat_test, sales_test, cv = 5, scoring = 'r2')
print('5-cross validation accuracy(test data)', (np.mean(score)), (np.std(score)))
```

```{python}
#view distribution plot of actual vs fitted of testing data - 
dis_data(sales_test, yhat_RF_test, 'Actual Values(test)', 'Predicted Values(test)', title = 'Distribution PLot of actual values of testing data vs predicted values of testing data')
```


We can see that the Random forest regressor performed best (having the lowest mean absolute error of 1783.60318 and high R-squared of 95%) compared to other models. Therefore, we pick this one to be our base model, and we will fine-tune the model in the next section.


# 5.Automate and Deploy the model
 


#### Automate pipeline
To deploy the selected model, a data pipeline will be created to automate the needed transformations once data is given as an input to the model.

```{python}
#create pipeline for random forest regression 
input = [('scale', StandardScaler()), ('model', RandomForestRegressor(n_estimators = 150, n_jobs = 2, max_features = 7))]
pipe = Pipeline(input)
pipe
```

```{python}
#fit the pipeline to the entire training data - 
RFmodel = pipe.fit(feat_df, sales_df)
```

The pipeline will Normalize and produce predictions ..



```{python}
#make predictions on the test data and print first five - 
ypipe = pipe.predict(feat_df)
ypipe[0:5]
```

Now the model will be saved so it can be used whenever needed.



```{python}
filename = 'Sales_forecasting_model.csv'
joblib.dump(RFmodel, filename)
```

We can now load the model to a variable and add new data to it -



```{python}
#load model 
loaded_m = joblib.load(filename)
```

```{python}
#see results of test data with known Weekly_Sales - 
result = loaded_m.score(feat_test, sales_test)
print(result)
```

```{python}
#PLot feature importances -
feat_importances = pd.Series(RF.feature_importances_, index=feat_df.columns)
feat_importances.nlargest(10).plot(kind='barh')
```


# Summary
Using a Random Forest Regressor Model gave the most accurate results. The result was a mean absolute error of 1783.6 with the accuracy of 95.7%.

This model can be used as a guide when determining Weekly_Sales since it results in a resonable predictions when given information on years of store, department, dates & whether it is a holdiay or not.
